{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MLflow でモデルをログする\n",
        "\n",
        "Azure Machine Learning の MLflow を使ってモデルのログを取ることができます。モデルをアーティファクトではなくモデルとしてログに記録すると、出力ディレクトリに MLmodel が作成されます。MLmodel ファイルには、モデルのすべてのメタデータが含まれます。モデルをログに記録する際に、モデルの署名をカスタマイズすることができます。\n",
        "\n",
        "## 始める前に\n",
        "\n",
        "このノートブックのコードを実行するには、**azure-ai-ml** パッケージの最新版が必要です。以下のセルを実行して、インストールされていることを確認してください。\n",
        "\n",
        "> 注**：\n",
        "> もし **azure-ai-ml** パッケージがインストールされていない場合は、`pip install azure-ai-ml` を実行してインストールしてください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1731375342034
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: azure-ai-ml\n",
            "Version: 1.21.1\n",
            "Summary: Microsoft Azure Machine Learning Client Library for Python\n",
            "Home-page: https://github.com/Azure/azure-sdk-for-python\n",
            "Author: Microsoft Corporation\n",
            "Author-email: azuresdkengsysadmins@microsoft.com\n",
            "License: MIT License\n",
            "Location: /anaconda/envs/azureml_py38/lib/python3.10/site-packages\n",
            "Requires: azure-common, azure-core, azure-mgmt-core, azure-storage-blob, azure-storage-file-datalake, azure-storage-file-share, colorama, isodate, jsonschema, marshmallow, msrest, opencensus-ext-azure, opencensus-ext-logging, pydash, pyjwt, pyyaml, strictyaml, tqdm, typing-extensions\n",
            "Required-by: \n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip show azure-ai-ml"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ワークスペースに接続する\n",
        "必要な SDK パッケージがインストールされ、ワークスペースに接続する準備が整いました。\n",
        "\n",
        "ワークスペースに接続するには、サブスクリプションID、リソースグループ名、ワークスペース名といった識別子のパラメータが必要だ。Azure Machine Learningが管理するコンピュートインスタンスで作業しているので、デフォルト値を使用してワークスペースに接続できる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1731375344414
        }
      },
      "outputs": [],
      "source": [
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1731375344470
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found the config file in: /config.json\n"
          ]
        }
      ],
      "source": [
        "# Get a handle to workspace\n",
        "ml_client = MLClient.from_config(credential=credential)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MLflow でのオートロギング\n",
        "\n",
        "オートロギングを使用すると、モデルは自動的にログに記録されます。モデルのフレーバーとスキーマは推測されます。\n",
        "\n",
        "以下のセルを実行して、**src** フォルダに **train-model-autolog.py** スクリプトを作成します。このスクリプトは、引数として渡された同じフォルダ内の **diabetes.csv** ファイルを使用して分類モデルを学習します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1731375344526
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "src folder created\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# create a folder for the script files\n",
        "script_folder = 'src'\n",
        "os.makedirs(script_folder, exist_ok=True)\n",
        "print(script_folder, 'folder created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting src/train-model-autolog.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile $script_folder/train-model-autolog.py\n",
        "# import libraries\n",
        "import mlflow\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def main(args):\n",
        "    # ログの有効化\n",
        "    mlflow.autolog()\n",
        "\n",
        "    # read data\n",
        "    df = get_data(args.training_data)\n",
        "\n",
        "    # split data\n",
        "    X_train, X_test, y_train, y_test = split_data(df)\n",
        "\n",
        "    # train model\n",
        "    model = train_model(args.reg_rate, X_train, X_test, y_train, y_test)\n",
        "\n",
        "    eval_model(model, X_test, y_test)\n",
        "\n",
        "# function that reads the data\n",
        "def get_data(path):\n",
        "    print(\"Reading data...\")\n",
        "    df = pd.read_csv(path)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# function that splits the data\n",
        "def split_data(df):\n",
        "    print(\"Splitting data...\")\n",
        "    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n",
        "    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# function that trains the model\n",
        "def train_model(reg_rate, X_train, X_test, y_train, y_test):\n",
        "    print(\"Training model...\")\n",
        "    model = LogisticRegression(C=1/reg_rate, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "    return model\n",
        "\n",
        "# function that evaluates the model\n",
        "def eval_model(model, X_test, y_test):\n",
        "    # calculate accuracy\n",
        "    y_hat = model.predict(X_test)\n",
        "    acc = np.average(y_hat == y_test)\n",
        "    print('Accuracy:', acc)\n",
        "\n",
        "def parse_args():\n",
        "    # setup arg parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # add arguments\n",
        "    parser.add_argument(\"--training_data\", dest='training_data',\n",
        "                        type=str)\n",
        "    parser.add_argument(\"--reg_rate\", dest='reg_rate',\n",
        "                        type=float, default=0.01)\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # return args\n",
        "    return args\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    # add space in logs\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"*\" * 60)\n",
        "\n",
        "    # parse args\n",
        "    args = parse_args()\n",
        "\n",
        "    # run main function\n",
        "    main(args)\n",
        "\n",
        "    # add space in logs\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "これで、スクリプトをコマンド・ジョブとして投入できる。\n",
        "以下のセルを実行してモデルをトレーニングします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1731375346469
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Monitor your job at https://ml.azure.com/runs/wheat_curtain_jdlm9cdrkf?wsid=/subscriptions/2fbd9cca-a295-4d4f-a5c4-bf80e223260f/resourcegroups/ai-900/workspaces/koikedemo&tid=adcb56ab-ed63-4be3-8e5e-2fa7d2eb44e1\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml import command\n",
        "\n",
        "# configure job\n",
        "\n",
        "job = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python train-model-autolog.py --training_data diabetes.csv\",\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
        "    compute=\"aml-cluster\",\n",
        "    display_name=\"diabetes-train-autolog\",\n",
        "    experiment_name=\"diabetes-training\"\n",
        "    )\n",
        "\n",
        "# submit job\n",
        "returned_job = ml_client.create_or_update(job)\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "スタジオで、**diabetes-train-autolog** ジョブに移動して、実行したコマンドジョブの概要を調べます。Outputs + logs** タブでログに記録されたアーティファクトを探します。model` フォルダを選択して `MLmodel` ファイルを見つけ、その中身を調べます。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## オートロギングでフレーバーを指定する\n",
        "\n",
        "オートロギングを使っても、モデルのフレーバーを指定することができます。この例では、モデルのフレーバーは scikit-learn です。\n",
        "\n",
        "以下のセルを実行して、**src** フォルダに **train-model-sklearn.py** スクリプトを作成します。このスクリプトは、引数として渡された同じフォルダ内の**diabetes.csv**ファイルを使用して分類モデルを学習します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting src/train-model-sklearn.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile $script_folder/train-model-sklearn.py\n",
        "# import libraries\n",
        "import mlflow\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def main(args):\n",
        "    # SKlearn のログ\n",
        "    mlflow.sklearn.autolog()\n",
        "\n",
        "    # read data\n",
        "    df = get_data(args.training_data)\n",
        "\n",
        "    # split data\n",
        "    X_train, X_test, y_train, y_test = split_data(df)\n",
        "\n",
        "    # train model\n",
        "    model = train_model(args.reg_rate, X_train, X_test, y_train, y_test)\n",
        "\n",
        "    eval_model(model, X_test, y_test)\n",
        "\n",
        "# function that reads the data\n",
        "def get_data(path):\n",
        "    print(\"Reading data...\")\n",
        "    df = pd.read_csv(path)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# function that splits the data\n",
        "def split_data(df):\n",
        "    print(\"Splitting data...\")\n",
        "    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n",
        "    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# function that trains the model\n",
        "def train_model(reg_rate, X_train, X_test, y_train, y_test):\n",
        "    print(\"Training model...\")\n",
        "    model = LogisticRegression(C=1/reg_rate, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "    return model\n",
        "\n",
        "# function that evaluates the model\n",
        "def eval_model(model, X_test, y_test):\n",
        "    # calculate accuracy\n",
        "    y_hat = model.predict(X_test)\n",
        "    acc = np.average(y_hat == y_test)\n",
        "    print('Accuracy:', acc)\n",
        "\n",
        "    # calculate AUC\n",
        "    y_scores = model.predict_proba(X_test)\n",
        "    auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "    print('AUC: ' + str(auc))\n",
        "\n",
        "    # plot ROC curve\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
        "    fig = plt.figure(figsize=(6, 4))\n",
        "    # Plot the diagonal 50% line\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    # Plot the FPR and TPR achieved by our model\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.savefig(\"ROC-Curve.png\") \n",
        "\n",
        "def parse_args():\n",
        "    # setup arg parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # add arguments\n",
        "    parser.add_argument(\"--training_data\", dest='training_data',\n",
        "                        type=str)\n",
        "    parser.add_argument(\"--reg_rate\", dest='reg_rate',\n",
        "                        type=float, default=0.01)\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # return args\n",
        "    return args\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    # add space in logs\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"*\" * 60)\n",
        "\n",
        "    # parse args\n",
        "    args = parse_args()\n",
        "\n",
        "    # run main function\n",
        "    main(args)\n",
        "\n",
        "    # add space in logs\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "これで、スクリプトをコマンド・ジョブとして投入できる。\n",
        "\n",
        "以下のセルを実行してモデルをトレーニングします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1731375348036
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Monitor your job at https://ml.azure.com/runs/plum_rhythm_kqhcqy6sj2?wsid=/subscriptions/2fbd9cca-a295-4d4f-a5c4-bf80e223260f/resourcegroups/ai-900/workspaces/koikedemo&tid=adcb56ab-ed63-4be3-8e5e-2fa7d2eb44e1\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml import command\n",
        "\n",
        "# configure job\n",
        "\n",
        "job = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python train-model-sklearn.py --training_data diabetes.csv\",\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
        "    compute=\"aml-cluster\",\n",
        "    display_name=\"diabetes-train-sklearn\",\n",
        "    experiment_name=\"diabetes-training\"\n",
        "    )\n",
        "\n",
        "# submit job\n",
        "returned_job = ml_client.create_or_update(job)\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "スタジオで、**diabetes-train-sklearn** ジョブに移動し、実行したコマンドジョブの概要を調べます。Outputs + logs** タブでログに記録された成果物を探します。model` フォルダを選択して `MLmodel` ファイルを見つけ、その内容を調べます。\n",
        "\n",
        "前の2つの実行の `MLmodel` ファイルを比較してください。MLflowのautolog機能がモデルのフレーバーを正しく推論していることがわかります。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 推測されたシグネチャでモデルをカスタマイズする\n",
        "\n",
        "自動ログではなく、`mlflow.sklearn.log_model`を使用して手動でモデルをログに記録することができます。学習データセットと予測結果からシグネチャを推測して作成します。そして最後に、scikit-learnモデルをログに記録します。\n",
        "\n",
        "以下のセルを実行して、**src** フォルダに **train-model-infer.py** スクリプトを作成します。このスクリプトは、引数として渡された同じフォルダ内の **diabetes.csv** ファイルを使用して分類モデルを学習します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting src/train-model-infer.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile $script_folder/train-model-infer.py\n",
        "# import libraries\n",
        "import mlflow\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import mlflow.sklearn\n",
        "from mlflow.models.signature import infer_signature\n",
        "\n",
        "def main(args):\n",
        "    # read data\n",
        "    df = get_data(args.training_data)\n",
        "\n",
        "    # split data\n",
        "    X_train, X_test, y_train, y_test = split_data(df)\n",
        "\n",
        "    # train model\n",
        "    model = train_model(args.reg_rate, X_train, X_test, y_train, y_test)\n",
        "\n",
        "    # evaluate model\n",
        "    y_hat = eval_model(model, X_test, y_test)\n",
        "\n",
        "    # create the signature by inferring it from the datasets\n",
        "    signature = infer_signature(X_train, y_hat)\n",
        "\n",
        "    # manually log the model\n",
        "    mlflow.sklearn.log_model(model, \"model\", signature=signature)\n",
        "\n",
        "# function that reads the data\n",
        "def get_data(path):\n",
        "    print(\"Reading data...\")\n",
        "    df = pd.read_csv(path)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# function that splits the data\n",
        "def split_data(df):\n",
        "    print(\"Splitting data...\")\n",
        "    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n",
        "    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# function that trains the model\n",
        "def train_model(reg_rate, X_train, X_test, y_train, y_test):\n",
        "    print(\"Training model...\")\n",
        "    model = LogisticRegression(C=1/reg_rate, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "    return model\n",
        "\n",
        "# function that evaluates the model\n",
        "def eval_model(model, X_test, y_test):\n",
        "    # calculate accuracy\n",
        "    y_hat = model.predict(X_test)\n",
        "    acc = np.average(y_hat == y_test)\n",
        "    print('Accuracy:', acc)\n",
        " \n",
        "    return y_hat\n",
        "\n",
        "def parse_args():\n",
        "    # setup arg parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # add arguments\n",
        "    parser.add_argument(\"--training_data\", dest='training_data',\n",
        "                        type=str)\n",
        "    parser.add_argument(\"--reg_rate\", dest='reg_rate',\n",
        "                        type=float, default=0.01)\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # return args\n",
        "    return args\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    # add space in logs\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"*\" * 60)\n",
        "\n",
        "    # parse args\n",
        "    args = parse_args()\n",
        "\n",
        "    # run main function\n",
        "    main(args)\n",
        "\n",
        "    # add space in logs\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "これで、スクリプトをコマンド・ジョブとして投入できる。\n",
        "\n",
        "以下のセルを実行してモデルをトレーニングします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1731375349046
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Monitor your job at https://ml.azure.com/runs/good_ear_0tzy7rc006?wsid=/subscriptions/2fbd9cca-a295-4d4f-a5c4-bf80e223260f/resourcegroups/ai-900/workspaces/koikedemo&tid=adcb56ab-ed63-4be3-8e5e-2fa7d2eb44e1\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml import command\n",
        "\n",
        "# configure job\n",
        "\n",
        "job = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python train-model-infer.py --training_data diabetes.csv\",\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
        "    compute=\"aml-cluster\",\n",
        "    display_name=\"diabetes-train-infer\",\n",
        "    experiment_name=\"diabetes-training\"\n",
        "    )\n",
        "\n",
        "# submit job\n",
        "returned_job = ml_client.create_or_update(job)\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "スタジオで、**diabetes-train-infer** ジョブに移動し、実行したコマンドジョブの概要を調べます。Outputs + logs** タブでログに記録されたアーティファクトを探します。model` フォルダを選択して `MLmodel` ファイルを見つけ、その内容を調べます。\n",
        "\n",
        "MLmodel`ファイルを前の2つの実行と比較してください。MLflowのautolog機能がモデルのシグネチャーも正しく推論していることがわかります。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 定義されたシグネチャでモデルをカスタマイズする\n",
        "\n",
        "mlflow.sklearn.log_model`を使ってモデルを手動でログに記録することができます。また、手動でシグネチャを作成します。そして最後に、scikit-learnモデルをログに記録します。\n",
        "\n",
        "以下のセルを実行して、**src** フォルダに **train-model-signature.py** スクリプトを作成します。このスクリプトは、引数として渡される同じフォルダ内の **diabetes.csv** ファイルを使用して分類モデルを学習します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting src/train-model-signature.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile $script_folder/train-model-signature.py\n",
        "# import libraries\n",
        "import mlflow\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import mlflow.sklearn\n",
        "from mlflow.models.signature import ModelSignature\n",
        "from mlflow.types.schema import Schema, ColSpec\n",
        "\n",
        "def main(args):\n",
        "    # read data\n",
        "    df = get_data(args.training_data)\n",
        "\n",
        "    # split data\n",
        "    X_train, X_test, y_train, y_test = split_data(df)\n",
        "\n",
        "    # train model\n",
        "    model = train_model(args.reg_rate, X_train, X_test, y_train, y_test)\n",
        "\n",
        "    # evaluate model\n",
        "    y_hat = eval_model(model, X_test, y_test)\n",
        "\n",
        "    # create the signature manually\n",
        "    input_schema = Schema([\n",
        "    ColSpec(\"integer\", \"Pregnancies\"),\n",
        "    ColSpec(\"integer\", \"PlasmaGlucose\"),\n",
        "    ColSpec(\"integer\", \"DiastolicBloodPressure\"),\n",
        "    ColSpec(\"integer\", \"TricepsThickness\"),\n",
        "    ColSpec(\"integer\", \"DiastolicBloodPressure\"),\n",
        "    ColSpec(\"integer\", \"SerumInsulin\"),\n",
        "    ColSpec(\"double\", \"BMI\"),\n",
        "    ColSpec(\"double\", \"DiabetesPedigree\"),\n",
        "    ColSpec(\"integer\", \"Age\"),\n",
        "    ])\n",
        "\n",
        "    output_schema = Schema([ColSpec(\"boolean\")])\n",
        "\n",
        "    # Create the signature object\n",
        "    signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
        "\n",
        "    # manually log the model\n",
        "    mlflow.sklearn.log_model(model, \"model\", signature=signature)\n",
        "\n",
        "# function that reads the data\n",
        "def get_data(path):\n",
        "    print(\"Reading data...\")\n",
        "    df = pd.read_csv(path)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# function that splits the data\n",
        "def split_data(df):\n",
        "    print(\"Splitting data...\")\n",
        "    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n",
        "    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# function that trains the model\n",
        "def train_model(reg_rate, X_train, X_test, y_train, y_test):\n",
        "    print(\"Training model...\")\n",
        "    model = LogisticRegression(C=1/reg_rate, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "    return model\n",
        "\n",
        "# function that evaluates the model\n",
        "def eval_model(model, X_test, y_test):\n",
        "    # calculate accuracy\n",
        "    y_hat = model.predict(X_test)\n",
        "    acc = np.average(y_hat == y_test)\n",
        "    print('Accuracy:', acc)\n",
        " \n",
        "    return y_hat\n",
        "\n",
        "def parse_args():\n",
        "    # setup arg parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # add arguments\n",
        "    parser.add_argument(\"--training_data\", dest='training_data',\n",
        "                        type=str)\n",
        "    parser.add_argument(\"--reg_rate\", dest='reg_rate',\n",
        "                        type=float, default=0.01)\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # return args\n",
        "    return args\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    # add space in logs\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"*\" * 60)\n",
        "\n",
        "    # parse args\n",
        "    args = parse_args()\n",
        "\n",
        "    # run main function\n",
        "    main(args)\n",
        "\n",
        "    # add space in logs\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "これで、スクリプトをコマンド・ジョブとして投入できる。\n",
        "\n",
        "以下のセルを実行してモデルをトレーニングします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1731375350288
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Monitor your job at https://ml.azure.com/runs/maroon_jackal_8lm92lh825?wsid=/subscriptions/2fbd9cca-a295-4d4f-a5c4-bf80e223260f/resourcegroups/ai-900/workspaces/koikedemo&tid=adcb56ab-ed63-4be3-8e5e-2fa7d2eb44e1\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml import command\n",
        "\n",
        "# configure job\n",
        "\n",
        "job = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python train-model-signature.py --training_data diabetes.csv\",\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
        "    compute=\"aml-cluster\",\n",
        "    display_name=\"diabetes-train-signature\",\n",
        "    experiment_name=\"diabetes-training\"\n",
        "    )\n",
        "\n",
        "# submit job\n",
        "returned_job = ml_client.create_or_update(job)\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "スタジオで、**diabetes-train-signature** ジョブに移動し、実行したコマンドジョブの概要を調べます。Outputs + logs** タブでログに記録されたアーティファクトを探します。model` フォルダを選択し、`MLmodel` ファイルを見つけ、その中身を調べます。\n",
        "\n",
        "MLmodel`ファイルを以前の実行と比較する。以前の実行とは署名が異なる。以前の実行ではテンソルベースのシグネチャを使用していたが、最新の実行では列ベースのシグネチャを使用している。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## モデルの登録\n",
        "\n",
        "デプロイしたいモデルを選択したら、まずモデルを登録します。\n",
        "\n",
        "最新のモデルを登録するには、ジョブの実行名を参照します。モデルをMLflowモデルとして登録することで、後で簡単にデプロイすることができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1731375351575
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Model\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "job_name = returned_job.name\n",
        "\n",
        "run_model = Model(\n",
        "    path=f\"azureml://jobs/{job_name}/outputs/artifacts/paths/model/\",\n",
        "    name=\"mlflow-diabetes\",\n",
        "    description=\"Model created from run.\",\n",
        "    type=AssetTypes.MLFLOW_MODEL,\n",
        ")\n",
        "# Uncomment after adding required details above\n",
        "ml_client.models.create_or_update(run_model)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "スタジオで、**Models** ページに移動します。モデルリストで `mlflow-diabetes` モデルを見つけて選択し、さらに調べます。\n",
        "\n",
        "- mlflow-diabetes`モデルの**Details** タブでは、`MLFLOW`タイプのモデルであることと、モデルをトレーニングしたジョブを確認することができます。\n",
        "- Artifacts**タブには `MLmodel` ファイルが格納されているディレクトリがあります。\n",
        "\n",
        "モデルの挙動をさらに調べたい場合は、**オプションで**モデルをリアルタイムエンドポイントにデプロイすることを選択できます。"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
